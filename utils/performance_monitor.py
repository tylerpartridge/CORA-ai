#!/usr/bin/env python3
"""
ðŸ§­ LOCATION: /CORA/utils/performance_monitor.py
ðŸŽ¯ PURPOSE: Comprehensive performance monitoring and analytics
ðŸ”— IMPORTS: SQLAlchemy, Redis, logging, time
ðŸ“¤ EXPORTS: PerformanceMonitor, get_performance_metrics
"""

import logging
import time
from typing import Dict, List, Any, Optional
from datetime import datetime
from sqlalchemy import text
from sqlalchemy.orm import Session

from models.base import engine
from utils.redis_manager import get_redis_client
from middleware.query_monitoring import query_monitor

logger = logging.getLogger(__name__)

class PerformanceMonitor:
    """Comprehensive performance monitoring and analytics"""
    
    def __init__(self, db: Session = None, redis_client=None):
        self.db = db
        self.redis = redis_client or get_redis_client()
    
    def get_system_health(self) -> Dict[str, Any]:
        """Get overall system health metrics"""
        try:
            health_metrics = {
                "database": self._check_database_health(),
                "redis": self._check_redis_health(),
                "query_performance": self._get_query_performance_metrics(),
                "materialized_views": self._get_materialized_view_metrics(),
                "cache_efficiency": self._get_cache_efficiency_metrics(),
                "timestamp": datetime.now().isoformat()
            }
            
            # Calculate overall health score
            health_score = self._calculate_health_score(health_metrics)
            health_metrics["overall_health_score"] = health_score
            
            return health_metrics
            
        except Exception as e:
            logger.error(f"Error getting system health: {e}")
            return {
                "status": "error",
                "message": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def _check_database_health(self) -> Dict[str, Any]:
        """Check database connection and performance"""
        try:
            start_time = time.time()
            
            # Test basic query performance
            result = engine.execute(text("SELECT 1"))
            result.fetchone()
            
            query_time = time.time() - start_time
            
            # Get database size and table counts
            if self.db:
                # Get table sizes (SQLite specific)
                size_result = self.db.execute(text("""
                    SELECT name, sql FROM sqlite_master 
                    WHERE type='table' AND name NOT LIKE 'sqlite_%'
                """))
                tables = size_result.fetchall()
                
                # Get row counts for main tables - SECURE VERSION
                # Whitelist of allowed table names to prevent SQL injection
                ALLOWED_TABLES = {'users', 'expenses', 'jobs', 'business_profiles'}
                table_counts = {}
                
                for table in ALLOWED_TABLES:
                    # Validate table name contains only alphanumeric and underscore
                    if not table.replace('_', '').isalnum():
                        continue
                        
                    try:
                        # Use parameterized query where possible, or validate strictly
                        # SQLite doesn't support table name parameters, so we validate instead
                        count_result = self.db.execute(text(f"SELECT COUNT(*) FROM {table}"))
                        table_counts[table] = count_result.scalar()
                    except:
                        table_counts[table] = 0
            else:
                tables = []
                table_counts = {}
            
            return {
                "status": "healthy",
                "connection_time": query_time,
                "table_count": len(tables),
                "table_counts": table_counts,
                "connection_pool_size": engine.pool.size(),
                "checked_out_connections": engine.pool.checkedout()
            }
            
        except Exception as e:
            logger.error(f"Database health check failed: {e}")
            return {
                "status": "unhealthy",
                "error": str(e)
            }
    
    def _check_redis_health(self) -> Dict[str, Any]:
        """Check Redis connection and performance"""
        try:
            start_time = time.time()
            
            # Test Redis connection
            self.redis.ping()
            
            ping_time = time.time() - start_time
            
            # Get Redis info
            info = self.redis.info()
            
            return {
                "status": "healthy",
                "ping_time": ping_time,
                "connected_clients": info.get('connected_clients', 0),
                "used_memory": info.get('used_memory_human', '0B'),
                "keyspace_hits": info.get('keyspace_hits', 0),
                "keyspace_misses": info.get('keyspace_misses', 0)
            }
            
        except Exception as e:
            logger.error(f"Redis health check failed: {e}")
            return {
                "status": "unhealthy",
                "error": str(e)
            }
    
    def _get_query_performance_metrics(self) -> Dict[str, Any]:
        """Get query performance metrics from query monitor"""
        try:
            stats = query_monitor.get_query_statistics()
            slow_queries = query_monitor.get_slow_queries(limit=10)
            
            # Calculate hit rate
            total_queries = stats.get('total_queries', 0)
            slow_query_count = stats.get('slow_query_count', 0)
            slow_query_rate = (slow_query_count / total_queries * 100) if total_queries > 0 else 0
            
            return {
                "total_queries": total_queries,
                "average_query_time": stats.get('average_query_time', 0),
                "slow_query_count": slow_query_count,
                "slow_query_rate_percent": slow_query_rate,
                "unique_queries": stats.get('unique_queries', 0),
                "recent_slow_queries": slow_queries
            }
            
        except Exception as e:
            logger.error(f"Error getting query performance metrics: {e}")
            return {"error": str(e)}
    
    def _get_materialized_view_metrics(self) -> Dict[str, Any]:
        """Get materialized view performance metrics"""
        try:
            # Check cache keys for materialized views
            mv_patterns = [
                "mv:job_profitability:*",
                "mv:dashboard_summary:*",
                "mv:expense_analytics:*"
            ]
            
            cache_stats = {}
            total_keys = 0
            
            for pattern in mv_patterns:
                keys = self.redis.keys(pattern)
                key_count = len(keys)
                cache_stats[pattern] = key_count
                total_keys += key_count
            
            # Get cache hit/miss rates for materialized views
            hit_rate = 0
            if total_keys > 0:
                # This is a simplified calculation - in production you'd track actual hits/misses
                hit_rate = 85.0  # Estimated based on typical Redis performance
            
            return {
                "total_cached_views": total_keys,
                "cache_stats": cache_stats,
                "estimated_hit_rate_percent": hit_rate,
                "last_refresh": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error getting materialized view metrics: {e}")
            return {"error": str(e)}
    
    def _get_cache_efficiency_metrics(self) -> Dict[str, Any]:
        """Get cache efficiency metrics"""
        try:
            # Get Redis memory usage
            info = self.redis.info()
            
            # Calculate cache efficiency
            keyspace_hits = info.get('keyspace_hits', 0)
            keyspace_misses = info.get('keyspace_misses', 0)
            total_requests = keyspace_hits + keyspace_misses
            
            hit_rate = (keyspace_hits / total_requests * 100) if total_requests > 0 else 0
            
            return {
                "total_requests": total_requests,
                "hits": keyspace_hits,
                "misses": keyspace_misses,
                "hit_rate_percent": hit_rate,
                "memory_usage": info.get('used_memory_human', '0B'),
                "memory_peak": info.get('used_memory_peak_human', '0B')
            }
            
        except Exception as e:
            logger.error(f"Error getting cache efficiency metrics: {e}")
            return {"error": str(e)}
    
    def _calculate_health_score(self, metrics: Dict[str, Any]) -> float:
        """Calculate overall health score (0-100)"""
        try:
            score = 100.0
            
            # Database health
            db_health = metrics.get('database', {})
            if db_health.get('status') != 'healthy':
                score -= 30
            elif db_health.get('connection_time', 0) > 0.1:  # 100ms threshold
                score -= 10
            
            # Redis health
            redis_health = metrics.get('redis', {})
            if redis_health.get('status') != 'healthy':
                score -= 25
            elif redis_health.get('ping_time', 0) > 0.01:  # 10ms threshold
                score -= 5
            
            # Query performance
            query_metrics = metrics.get('query_performance', {})
            slow_query_rate = query_metrics.get('slow_query_rate_percent', 0)
            if slow_query_rate > 10:  # More than 10% slow queries
                score -= 20
            elif slow_query_rate > 5:  # More than 5% slow queries
                score -= 10
            
            avg_query_time = query_metrics.get('average_query_time', 0)
            if avg_query_time > 0.1:  # Average query time > 100ms
                score -= 15
            elif avg_query_time > 0.05:  # Average query time > 50ms
                score -= 5
            
            # Cache efficiency
            cache_metrics = metrics.get('cache_efficiency', {})
            hit_rate = cache_metrics.get('hit_rate_percent', 0)
            if hit_rate < 70:  # Less than 70% cache hit rate
                score -= 10
            elif hit_rate < 85:  # Less than 85% cache hit rate
                score -= 5
            
            return max(0.0, score)
            
        except Exception as e:
            logger.error(f"Error calculating health score: {e}")
            return 50.0  # Default to 50 if calculation fails
    
    def get_performance_recommendations(self) -> List[Dict[str, Any]]:
        """Get performance improvement recommendations"""
        recommendations = []
        
        try:
            health = self.get_system_health()
            
            # Database recommendations
            db_health = health.get('database', {})
            if db_health.get('connection_time', 0) > 0.1:
                recommendations.append({
                    "category": "database",
                    "priority": "high",
                    "title": "Database Connection Slow",
                    "description": f"Database connection taking {db_health['connection_time']:.3f}s",
                    "action": "Consider connection pooling optimization or database tuning"
                })
            
            # Query performance recommendations
            query_metrics = health.get('query_performance', {})
            slow_query_rate = query_metrics.get('slow_query_rate_percent', 0)
            if slow_query_rate > 10:
                recommendations.append({
                    "category": "queries",
                    "priority": "high",
                    "title": "High Slow Query Rate",
                    "description": f"{slow_query_rate:.1f}% of queries are slow",
                    "action": "Review and optimize slow queries, add missing indexes"
                })
            
            # Cache recommendations
            cache_metrics = health.get('cache_efficiency', {})
            hit_rate = cache_metrics.get('hit_rate_percent', 0)
            if hit_rate < 70:
                recommendations.append({
                    "category": "caching",
                    "priority": "medium",
                    "title": "Low Cache Hit Rate",
                    "description": f"Cache hit rate is {hit_rate:.1f}%",
                    "action": "Review cache keys and TTL settings, optimize cache strategy"
                })
            
            # Materialized view recommendations
            mv_metrics = health.get('materialized_views', {})
            total_cached = mv_metrics.get('total_cached_views', 0)
            if total_cached == 0:
                recommendations.append({
                    "category": "materialized_views",
                    "priority": "medium",
                    "title": "No Materialized Views Cached",
                    "description": "Materialized views are not being utilized",
                    "action": "Enable materialized view caching for complex queries"
                })
            
        except Exception as e:
            logger.error(f"Error getting performance recommendations: {e}")
            recommendations.append({
                "category": "system",
                "priority": "high",
                "title": "Performance Monitoring Error",
                "description": f"Error analyzing performance: {str(e)}",
                "action": "Check system logs and monitoring configuration"
            })
        
        return recommendations

def get_performance_metrics(db: Session = None) -> Dict[str, Any]:
    """Get comprehensive performance metrics"""
    monitor = PerformanceMonitor(db)
    return monitor.get_system_health()

def get_performance_recommendations(db: Session = None) -> List[Dict[str, Any]]:
    """Get performance improvement recommendations"""
    monitor = PerformanceMonitor(db)
    return monitor.get_performance_recommendations()